# Story 8.5: Data Quality Issue Flagging

## Status

**Draft**

## Story

**As a** user,
**I want** data quality issues and inference-based results clearly flagged in all reports,
**so that** I understand the reliability of information for each lab.

## Acceptance Criteria

1. Data quality flags embedded throughout reports (FR32)
2. Flags for: missing websites, inferred lab members, low-confidence matches, missing publications, stale data
3. Consistent flag format (e.g., "⚠️ Lab members inferred from co-authorship")
4. Severity levels indicated (info, caution, warning)
5. Summary of data quality issues in each lab report
6. Overall data quality metrics in Overview.md
7. Flags help user assess information reliability

## Tasks / Subtasks

- [ ] **Task 1: Collect All Data Quality Flags** (AC: 1, 2)
  - [ ] Aggregate flags from all models
  - [ ] Categorize by type

- [ ] **Task 2: Format Flags Consistently** (AC: 3, 4)
  - [ ] Use emoji indicators: ⚠️, ℹ️, ❌
  - [ ] Show severity levels

- [ ] **Task 3: Add to Lab Reports** (AC: 5)
  - [ ] Include data quality section in each lab report
  - [ ] List all issues found

- [ ] **Task 4: Add to Overview** (AC: 6)
  - [ ] Show overall data quality metrics
  - [ ] Summary of common issues

- [ ] **Task 5: Provide Context** (AC: 7)
  - [ ] Explain what each flag means
  - [ ] Help user assess reliability

## Dev Notes

### Source Tree Location
- Modify: `src/agents/report_generator.py`

**Flag Format Examples:**
- `⚠️ Lab members inferred from co-authorship`
- `ℹ️ Website last updated 3 years ago`
- `❌ No LinkedIn profiles found`

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-06 | 0.1 | Initial story creation | Sarah (PO) |
