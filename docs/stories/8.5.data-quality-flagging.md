# Story 8.5: Data Quality Issue Flagging

## Status

**Draft**

## Story

**As a** user,
**I want** data quality issues and inference-based results clearly flagged in all reports,
**so that** I understand the reliability of information for each lab.

## Acceptance Criteria

1. Data quality flags embedded throughout reports (FR32)
2. Flags for: missing websites, inferred lab members, low-confidence matches, missing publications, stale data
3. Consistent flag format (e.g., "⚠️ Lab members inferred from co-authorship")
4. Severity levels indicated (info, caution, warning)
5. Summary of data quality issues in each lab report
6. Overall data quality metrics in Overview.md
7. Flags help user assess information reliability

## Tasks / Subtasks

- [ ] **Task 1: Collect All Data Quality Flags** (AC: 1, 2)
  - [ ] Aggregate flags from all models
  - [ ] Categorize by type

- [ ] **Task 2: Format Flags Consistently** (AC: 3, 4)
  - [ ] Use emoji indicators: ⚠️, ℹ️, ❌
  - [ ] Show severity levels

- [ ] **Task 3: Add to Lab Reports** (AC: 5)
  - [ ] Include data quality section in each lab report
  - [ ] List all issues found

- [ ] **Task 4: Add to Overview** (AC: 6)
  - [ ] Show overall data quality metrics
  - [ ] Summary of common issues

- [ ] **Task 5: Provide Context** (AC: 7)
  - [ ] Explain what each flag means
  - [ ] Help user assess reliability

## Dev Notes

### Source Tree Location
- Modify: `src/agents/report_generator.py`
- Modify: `output/Overview.md` (add data quality summary)
- Modify: `output/labs/*.md` (add flags to individual reports from Story 8.4)

### Dependencies
- Flags collected from Lab objects populated during Epic 4-7 processing
- Integrated into reports created in Stories 8.1 and 8.4

### Input Data
- Lab data from: `checkpoints/phase-7-fitness-scores.jsonl`
- Each Lab object contains `data_quality_flags` list populated during processing

### Flag Sources by Epic
- **Epic 4 (Lab Intelligence):**
  - Missing website: `lab.website_status == None or lab.website_url == None`
  - Stale website: `lab.website_last_updated < (current_date - 2 years)`
  - Missing contact info: `lab.contact_info.email == None`
  - Archive.org fallback used: `lab.website_source == "archive.org"`

- **Epic 5 (Publications):**
  - No publications found: `len(lab.publications) == 0`
  - Inferred lab members: `lab.members_source == "co-authorship"`
  - Missing abstracts: `publication.abstract == None`

- **Epic 6 (LinkedIn):**
  - No LinkedIn profiles found: `len(lab.linkedin_matches) == 0`
  - Low-confidence matches: `linkedin_match.confidence < 70`
  - LinkedIn unavailable: LinkedIn access failed or rate limited

- **Epic 7 (Scoring):**
  - Partial scoring: Some criteria couldn't be evaluated due to missing data
  - Low confidence score: Fitness score has high uncertainty

### Severity Level Definitions

**ℹ️ INFO (Informational):**
- Does not significantly impact reliability
- User should be aware but not concerned
- Examples:
  - `ℹ️ Website last updated 8 months ago`
  - `ℹ️ Some publication abstracts unavailable`
  - `ℹ️ LinkedIn confidence score 72% (moderate)`

**⚠️ CAUTION (May Affect Confidence):**
- Reduces confidence in some data, but workarounds applied
- User should consider when making decisions
- Examples:
  - `⚠️ Lab members inferred from co-authorship (website unavailable)`
  - `⚠️ Website data from Archive.org snapshot (current site inaccessible)`
  - `⚠️ Low LinkedIn match confidence (< 70%)`
  - `⚠️ Contact information not found on website`

**❌ WARNING (Significant Data Gap):**
- Major data missing, reliability significantly impacted
- User should investigate further before contacting
- Examples:
  - `❌ No LinkedIn profiles found for any lab members`
  - `❌ No publications found in last 3 years`
  - `❌ Lab website unavailable (no Archive.org snapshots)`
  - `❌ Fitness scoring incomplete due to missing data`

### Flag Aggregation Logic
```python
# Collect all flags from Lab object
def collect_flags(lab: Lab) -> list[DataQualityFlag]:
    flags = []

    # Website flags
    if not lab.website_url:
        flags.append(Flag(severity="WARNING", message="Lab website unavailable"))
    elif lab.website_last_updated and (now() - lab.website_last_updated).years >= 2:
        flags.append(Flag(severity="CAUTION", message=f"Website last updated {lab.website_last_updated}"))

    # Member flags
    if lab.members_source == "co-authorship":
        flags.append(Flag(severity="CAUTION", message="Lab members inferred from co-authorship"))

    # Publication flags
    if len(lab.publications) == 0:
        flags.append(Flag(severity="WARNING", message="No publications found in last 3 years"))

    # LinkedIn flags
    if len(lab.linkedin_matches) == 0:
        flags.append(Flag(severity="WARNING", message="No LinkedIn profiles found"))
    low_confidence = [m for m in lab.linkedin_matches if m.confidence < 70]
    if low_confidence:
        flags.append(Flag(severity="CAUTION", message=f"{len(low_confidence)} low-confidence LinkedIn matches"))

    return flags
```

### Overall Data Quality Metrics Format
Display in Overview.md:
```markdown
## Data Quality Summary

**Total Labs Analyzed:** 45

| Issue Type | Count | % of Labs |
|------------|-------|-----------|
| ❌ No publications found | 2 | 4% |
| ❌ Website unavailable | 5 | 11% |
| ⚠️ Inferred lab members | 8 | 18% |
| ⚠️ Stale website (>2 years) | 12 | 27% |
| ℹ️ Some LinkedIn matches low confidence | 15 | 33% |

**Labs with Critical Issues (❌):** 7 (16%)
**Labs with Cautions (⚠️):** 20 (44%)
**Labs with Complete Data:** 18 (40%)
```

### Flag Display in Reports

**In Individual Lab Reports (Story 8.4):**
- Section 9 "Data Quality Notes" lists all flags for that lab
- Each flag shows: Severity emoji + message + optional explanation

**In Overview.md (Story 8.1):**
- Summary table showing count and percentage of each issue type
- Aggregate statistics (% of labs with critical issues, complete data, etc.)

**Flag Format Examples:**
- `⚠️ Lab members inferred from co-authorship` - CAUTION level
- `ℹ️ Website last updated 8 months ago` - INFO level
- `❌ No LinkedIn profiles found` - WARNING level
- `⚠️ Contact information not found on website` - CAUTION level
- `ℹ️ 2 publications missing abstracts` - INFO level

## Testing

### Testing Approach
- **Unit Tests:** Flag collection logic, severity level assignment, aggregation calculations
- **Integration Tests:** Flags displayed correctly in both Overview.md and individual lab reports

### Key Test Scenarios
1. **Happy Path:** Labs with various flag types across all severity levels, verify correct classification
2. **Edge Case - No Flags:** Lab with complete data, verify "No data quality issues" message
3. **Edge Case - All Critical:** Lab with only ❌ WARNING flags, verify high-visibility display
4. **Edge Case - Zero Labs:** Handle empty lab list in aggregate statistics
5. **Validation:** Flag sources match actual data conditions (missing website → flag present)
6. **Validation:** Severity levels assigned correctly per definition
7. **Validation:** Aggregate statistics math correct (counts and percentages)
8. **Validation:** Flags appear in both Overview.md summary and individual lab reports

### Success Criteria
- All data quality issues flagged with correct severity
- Consistent flag format (emoji + message) across all reports
- Overview.md contains aggregate data quality summary table
- Individual lab reports (Story 8.4) contain lab-specific flags
- Severity level distribution accurate (INFO/CAUTION/WARNING counts)
- Flags help user understand data reliability and limitations
- No duplicate flags for same issue

## References

### Related Documentation
- **PRD:** Epic 8 Data Quality Flagging (docs/prd.md:863-877)
- **PRD:** FR32 Data Quality Documentation (docs/prd.md:106)
- **Architecture:** Report Generator component (docs/architecture.md:1307-1319)
- **Architecture:** Graceful Degradation strategies (referenced throughout architecture)

### Dependencies
- **Stories 8.1 & 8.4:** Flags integrated into Overview.md and individual lab reports
- **Epic 7:** Fitness scoring (may generate scoring quality flags)
- **Epic 6:** LinkedIn Integration (generates match confidence and availability flags)
- **Epic 5:** Publications (generates inference and missing data flags)
- **Epic 4:** Lab Intelligence (generates website and contact info flags)

### Data Sources
- Lab objects from: `checkpoints/phase-7-fitness-scores.jsonl`
- Each Lab object's `data_quality_flags` field contains flags added during Epic 4-7
- Flag structure:
  ```python
  class DataQualityFlag:
      severity: str  # "INFO", "CAUTION", "WARNING"
      message: str   # Human-readable description
      source_epic: int  # Which epic generated this flag (4-7)
      field_affected: str  # Which data field has the issue
  ```

### Cross-Epic Flag Consistency
Flags must be populated during processing in Epic 4-7 stories:
- **Epic 4 stories:** Set website, contact, and member discovery flags
- **Epic 5 stories:** Set publication and inference flags
- **Epic 6 stories:** Set LinkedIn match and confidence flags
- **Epic 7 stories:** Set scoring confidence flags
- **Story 8.5:** Aggregates all flags for display (does NOT generate new flags)

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-06 | 0.1 | Initial story creation | Sarah (PO) |
