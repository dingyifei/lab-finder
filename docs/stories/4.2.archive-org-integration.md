# Story 4.2: Archive.org Integration for Website History

## Status

**Draft**

## Story

**As a** user,
**I want** website change history analyzed using Archive.org Wayback Machine,
**so that** I can identify stale labs with outdated websites.

## Acceptance Criteria

1. Archive.org API queried for each lab website (FR14)
2. Most recent snapshot date identified
3. Snapshot dates over past 3 years collected
4. Change frequency calculated (e.g., updated monthly, yearly, not updated)
5. If current site unavailable, most recent snapshot used
6. Archive.org rate limiting respected (NFR11)
7. Missing snapshots handled gracefully (not all sites archived)

## Tasks / Subtasks

- [ ] **Task 1: Integrate Archive.org Wayback Machine API** (AC: 1)
  - [ ] Install wayback library: `pip install waybackpy`
  - [ ] Create wrapper function `query_wayback_snapshots(url: str) -> list[dict]`
  - [ ] Query API for snapshot availability
  - [ ] Extract snapshot dates and URLs
  - [ ] Handle API errors gracefully

- [ ] **Task 2: Find Most Recent Snapshot** (AC: 2, 5)
  - [ ] Query API for most recent snapshot of lab URL
  - [ ] Extract snapshot date
  - [ ] If current site unavailable (404), fetch most recent archived version
  - [ ] Store snapshot date in Lab.last_wayback_snapshot field
  - [ ] Log: "Most recent snapshot: {date} for {lab_url}"

- [ ] **Task 3: Collect 3-Year Snapshot History** (AC: 3)
  - [ ] Query snapshots from last 3 years
  - [ ] Filter to significant snapshots (avoid duplicates)
  - [ ] Extract dates for analysis
  - [ ] Store in Lab.wayback_snapshots: list[datetime]

- [ ] **Task 4: Calculate Update Frequency** (AC: 4)
  - [ ] Analyze snapshot date intervals
  - [ ] Calculate frequency:
    - Weekly: <1 month between snapshots
    - Monthly: 1-3 months
    - Quarterly: 3-6 months
    - Yearly: 6-18 months
    - Stale: >18 months
  - [ ] Store in Lab.update_frequency: str
  - [ ] Use for website freshness scoring

- [ ] **Task 5: Respect Rate Limiting** (AC: 6)
  - [ ] Implement rate limiting: Max 15 requests/minute to Wayback API
  - [ ] Use asyncio.sleep() between requests
  - [ ] Add retry logic for 429 (Too Many Requests) responses
  - [ ] Log rate limiting pauses

- [ ] **Task 6: Handle Missing Archive Data** (AC: 7)
  - [ ] If no snapshots found: Flag with "no_archive_data"
  - [ ] If API fails: Flag with "archive_query_failed"
  - [ ] Don't fail processing for missing archive data
  - [ ] Log: "{X} labs have no Wayback Machine data"

- [ ] **Task 7: Update Lab Model with Archive Fields** (AC: 2, 3, 4)
  - [ ] Add to Lab model:
    ```python
    last_wayback_snapshot: Optional[datetime] = None
    wayback_snapshots: list[datetime] = []
    update_frequency: str = "unknown"  # weekly/monthly/yearly/stale
    ```

- [ ] **Task 8: Integrate with Lab Research Agent** (AC: 1)
  - [ ] Call Archive.org query after lab website scraping
  - [ ] Run in batch to respect rate limits
  - [ ] Save results to lab checkpoint
  - [ ] Update progress: "Analyzing website history [X/Y]"

## Dev Notes

### Relevant Architecture Information

**Component:** Lab Research Agent - Archive.org Module (Epic 4)

**Responsibility:** Query Wayback Machine for website change history (Epic 4: FR14)

**Key Interfaces:**
- `query_wayback_snapshots(url: str) -> list[dict]` - Get snapshot history
- `calculate_update_frequency(snapshots: list[datetime]) -> str` - Determine freshness

**Dependencies:**
- waybackpy library for Wayback Machine API
- Lab data from Story 4.1
- Rate limiting utilities

**Technology Stack:**
- waybackpy 3.0+ for Wayback Machine API
- Python datetime for date handling
- asyncio for rate limiting

**Source Tree Location:**
- Modify: `src/agents/lab_research.py` (add archive integration)
- Modify: `src/models/lab.py` (add archive fields)

**Archive.org API Usage:**
```python
from waybackpy import WaybackMachineCDXServerAPI

# Query snapshots
cdx = WaybackMachineCDXServerAPI(url, user_agent="LabFinder/1.0")
snapshots = cdx.snapshots()

# Get most recent
newest = cdx.newest()
```

**Update Frequency Calculation:**
```python
def calculate_update_frequency(snapshots: list[datetime]) -> str:
    if len(snapshots) < 2:
        return "unknown"

    intervals = []
    for i in range(1, len(snapshots)):
        delta = (snapshots[i] - snapshots[i-1]).days
        intervals.append(delta)

    avg_interval = sum(intervals) / len(intervals)

    if avg_interval < 30:
        return "weekly"
    elif avg_interval < 90:
        return "monthly"
    elif avg_interval < 180:
        return "quarterly"
    elif avg_interval < 545:
        return "yearly"
    else:
        return "stale"
```

**Rate Limiting Pattern:**
```python
import asyncio
from datetime import datetime, timedelta

class RateLimiter:
    def __init__(self, max_requests: int, time_window: timedelta):
        self.max_requests = max_requests
        self.time_window = time_window
        self.requests = []

    async def wait_if_needed(self):
        now = datetime.now()
        # Remove old requests outside time window
        self.requests = [r for r in self.requests if now - r < self.time_window]

        if len(self.requests) >= self.max_requests:
            # Wait until oldest request expires
            wait_time = (self.requests[0] + self.time_window - now).total_seconds()
            await asyncio.sleep(wait_time)

        self.requests.append(now)
```

**Updated Lab Model (with Archive Fields):**
```python
class Lab(BaseModel):
    id: str
    professor_id: str
    professor_name: str
    department: str
    lab_name: str
    lab_url: Optional[str] = None
    last_updated: Optional[datetime] = None  # From website
    description: str = ""
    research_focus: list[str] = []
    news_updates: list[str] = []
    website_content: str = ""
    data_quality_flags: list[str] = []
    # Archive.org fields (Story 4.2)
    last_wayback_snapshot: Optional[datetime] = None
    wayback_snapshots: list[datetime] = []
    update_frequency: str = "unknown"  # weekly/monthly/quarterly/yearly/stale
```

**Error Handling Pattern (from Architecture):**
- Retry Policy: Exponential backoff for API failures (max 3 retries)
- Timeout: 10 seconds per Archive.org API query
- Rate Limiting: 15 requests/minute to Archive.org
- Missing Data: Flag with "no_archive_data", continue processing
- API Failures: Flag with "archive_query_failed", log error

**Critical Rules (from Coding Standards):**
- Respect Archive.org rate limits (15 req/min)
- Handle missing archive data gracefully
- Never use print() for logging (use structlog)
- Always type hint function signatures
- Use checkpoint_manager.save_batch() - never write JSONL directly

**Architecture Component Diagram Flow:**
```
Lab Research Agent → Archive.org Query (waybackpy)
  ↓
Rate Limiter (15 req/min)
  ↓
Snapshot Data Extraction
  ↓
Update Frequency Calculator
  ↓
Lab Model Update (archive fields)
  ↓
Checkpoint Manager (save updated lab data)
  ↓
Progress Tracker (update progress)
```

### Testing

**Test File Location:** `tests/unit/test_archive_integration.py`

**Testing Standards:**
- Framework: pytest 7.4.4
- Mock Archive.org API responses
- Coverage requirement: 70% minimum

**Test Requirements:**
1. Unit test for query_wayback_snapshots with mocked API
2. Test most recent snapshot identification
3. Test 3-year snapshot collection
4. Test update frequency calculation (all categories: weekly/monthly/yearly/stale)
5. Test rate limiting enforcement
6. Test missing archive data handling
7. Test API failure graceful degradation
8. Integration test with mock waybackpy responses

**Example Test Pattern:**
```python
def test_calculate_update_frequency_monthly(mocker):
    # Arrange
    snapshots = [
        datetime(2025, 1, 1),
        datetime(2025, 2, 15),
        datetime(2025, 4, 1),
        datetime(2025, 5, 20)
    ]

    # Act
    frequency = calculate_update_frequency(snapshots)

    # Assert
    assert frequency == "monthly"  # Average ~45 days
```

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-06 | 0.1 | Initial story creation | Sarah (PO) |

## Dev Agent Record

### Agent Model Used

_To be populated by dev agent_

## QA Results

_To be populated by QA agent_
