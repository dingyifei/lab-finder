# Story 8.1: Overview Report with Ranked Labs

## Status

**Draft**

## Story

**As a** user,
**I want** an Overview.md report showing all labs ranked by fitness,
**so that** I can quickly identify top candidate labs.

## Acceptance Criteria

1. Overview.md generated in markdown format (FR26)
2. Labs listed in descending fitness score order
3. Each lab entry includes: PI name, department, fitness score, key highlights
4. Summary statistics provided (total labs analyzed, date range, etc.)
5. Scoring methodology summary included
6. Report saved to output directory
7. Human-readable formatting for easy review

## Tasks / Subtasks

- [ ] **Task 1: Load All Lab Data** (AC: 1)
  - [ ] Load labs from checkpoints
  - [ ] Ensure all have fitness scores

- [ ] **Task 2: Sort Labs by Fitness** (AC: 2)
  - [ ] Sort descending by fitness_score
  - [ ] Prepare ranked list

- [ ] **Task 3: Generate Report Content** (AC: 3, 4, 5)
  - [ ] Create markdown report
  - [ ] Include lab entries with highlights
  - [ ] Add summary statistics
  - [ ] Include scoring methodology

- [ ] **Task 4: Save Report** (AC: 6, 7)
  - [ ] Save to `output/Overview.md`
  - [ ] Format for readability

## Dev Notes

### Source Tree Location
- Create: `src/agents/report_generator.py`
- Create: `output/Overview.md`

### Input Data
- Load from: `checkpoints/phase-7-fitness-scores.jsonl`
- Data model: `FitnessScore` containing Lab object with all collected intelligence
- Dependencies: Requires Epic 7 completion (fitness scoring)

### Key Interfaces
- `generate_overview(ranked_labs: list[FitnessScore]) -> str` - Create ranked overview report
- See architecture.md:1307-1319 for complete Report Generator interface

### Key Highlights Definition
Each lab entry should include:
- Top 3 recent publications (by journal reputation)
- Position availability signals (graduating PhDs from Epic 6)
- Research alignment score highlights
- Notable collaborations (if any)

### Scoring Methodology Summary
Include summary of:
- Criteria used for fitness scoring (from Epic 7 LLM-identified criteria)
- Weighting factors applied
- Brief explanation of scoring scale (0-100)

## Testing

### Testing Approach
- **Unit Tests:** Report generation logic, markdown formatting functions
- **Integration Tests:** End-to-end report generation from checkpoint data

### Key Test Scenarios
1. **Happy Path:** 50 labs with complete data, verify correct ranking and all fields populated
2. **Edge Case - Empty Results:** Handle empty lab list gracefully with informative message
3. **Edge Case - Incomplete Data:** Labs with missing publications or member data render correctly
4. **Edge Case - Ranking Ties:** Multiple labs with identical fitness scores handled consistently
5. **Validation:** Summary statistics match actual lab count and date ranges

### Success Criteria
- All acceptance criteria verified programmatically
- Report renders correctly in markdown viewer
- Rankings are in correct descending order
- No missing or null fields in required sections

## References

### Related Documentation
- **PRD:** Epic 8 overview (docs/prd.md:800-878)
- **Architecture:** Report Generator component (docs/architecture.md:1307-1319)
- **Architecture:** System flow Phase 8 (docs/architecture.md:127-129)

### Dependencies
- **Epic 7:** Fitness Scoring (provides ranked FitnessScore objects)
- **Epic 6:** LinkedIn Integration (provides position availability data)
- **Epic 5:** Publication Research (provides publication data for highlights)
- **Epic 4:** Lab Intelligence (provides lab website and contact data)

### Data Models
- `FitnessScore`: Contains overall score, per-criterion scores, rationale, and Lab object
- `Lab`: Contains PI info, department, publications, members, website status, contact info
- See architecture.md for complete model definitions

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-06 | 0.1 | Initial story creation | Sarah (PO) |
