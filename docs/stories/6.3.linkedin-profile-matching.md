# Story 6.3: LinkedIn Profile Matching with Confidence Scores

## Status

**Draft**

## Story

**As a** user,
**I want** lab members matched to LinkedIn profiles with confidence scores,
**so that** I can assess match reliability and avoid false positives.

## Acceptance Criteria

1. LinkedIn search performed for each lab member (FR22)
2. Candidate profiles evaluated by LLM
3. Matching considers: name, university affiliation, degree program, timeline
4. Confidence score (0-100) generated for each match (FR22)
5. School affiliation differences easily identified (reduces false positives)
6. Low-confidence matches flagged for user review
7. No match found handled gracefully (not all members have LinkedIn)

## Tasks / Subtasks

- [ ] **Task 1: Search LinkedIn for Each Member** (AC: 1)
  - [ ] Use mcp-linkedin search_people tool
  - [ ] Query: name + university filters
  - [ ] Get top candidate profiles

- [ ] **Task 2: LLM-Based Profile Matching** (AC: 2, 3, 4)
  - [ ] Use `llm_helpers.call_llm_with_retry()` from Story 1.7
  - [ ] Use LinkedIn matching prompt template from llm_helpers
  - [ ] Consider: name match, university affiliation, education timeline
  - [ ] Parse LLM response to extract confidence score (0-100)
  - [ ] Load confidence threshold from config.json (`confidence_thresholds.linkedin_match`, default: 75.0)

- [ ] **Task 3: Identify Affiliation Mismatches** (AC: 5)
  - [ ] Check if university matches
  - [ ] Flag different institutions

- [ ] **Task 4: Handle No Match** (AC: 7)
  - [ ] If no good match: Set linkedin_url = None
  - [ ] Flag: "no_linkedin_profile"

- [ ] **Task 5: Create LabMember Model** (AC: 1, 4)
  - [ ] Create `src/models/lab_member.py`
  - [ ] Fields:
    ```python
    class LabMember(BaseModel):
        name: str
        linkedin_url: Optional[str] = None
        linkedin_match_confidence: int = 0
        entry_year: Optional[int] = None
        data_quality_flags: list[str] = []
    ```

## Dev Notes

### Source Tree Location
- Modify: `src/agents/linkedin_matcher.py`
- Create: `src/models/lab_member.py`
- Use: `src/utils/llm_helpers.py` (from Story 1.7)
- Use: `src/utils/logger.py` (from Story 1.7)

### LLM Integration for Profile Matching

**Use LLM Helpers from Story 1.7:**

Story 1.7 provides centralized LLM prompt templates in `src/utils/llm_helpers.py`, including:
- `LINKEDIN_PROFILE_MATCH_TEMPLATE` - Template for matching lab members to LinkedIn profiles
- `call_llm_with_retry(prompt: str, max_retries: int = 3) -> str` - LLM invocation with retry logic

**LLM Matching Pattern:**

```python
from src.utils.llm_helpers import call_llm_with_retry, LINKEDIN_PROFILE_MATCH_TEMPLATE
from src.utils.logger import get_logger
import json
import re

logger = get_logger(correlation_id=run_id, phase="linkedin_matching", component="profile_matcher")

async def match_profile_with_llm(member: LabMember, profile: dict, university: str) -> tuple[int, str]:
    """
    Use LLM to evaluate if LinkedIn profile matches lab member.

    Returns:
        tuple[int, str]: (confidence_score, reasoning)
    """
    # Format prompt using template
    prompt = LINKEDIN_PROFILE_MATCH_TEMPLATE.format(
        member_name=member.name,
        university=university,
        profile_name=profile.get('name', ''),
        headline=profile.get('headline', ''),
        education=profile.get('education', '')
    )

    # Call LLM with retry
    response = await call_llm_with_retry(prompt, max_retries=3)

    # Parse response for confidence score
    match = re.search(r'confidence[:\s]+(\d+)', response, re.IGNORECASE)
    confidence = int(match.group(1)) if match else 0

    logger.debug("LLM match evaluation", member=member.name, confidence=confidence, response=response)

    return confidence, response
```

### Confidence Threshold Configuration

**Source:** `config.json` (validated by Story 1.2 JSON schema)

**Schema Path:** `confidence_thresholds.linkedin_match`
- **Type:** number (0-100)
- **Default:** 75.0
- **Description:** Minimum confidence for LinkedIn profile matching

**Loading Configuration:**

```python
from src.utils.config_loader import load_config

config = load_config("config.json")
confidence_threshold = config.get("confidence_thresholds", {}).get("linkedin_match", 75.0)

# Use threshold
if confidence >= confidence_threshold:
    member.linkedin_url = profile['url']
    member.linkedin_match_confidence = confidence
else:
    logger.warning("Low confidence match", member=member.name, confidence=confidence, threshold=confidence_threshold)
    member.data_quality_flags.append("low_confidence_linkedin_match")
```

### Expanded LLM Matching Prompt Template

**Template from `llm_helpers.py` (Story 1.7):**

```python
LINKEDIN_PROFILE_MATCH_TEMPLATE = """
You are evaluating whether a LinkedIn profile matches a lab member.

Lab Member Information:
- Name: {member_name}
- University: {university}
- Context: Listed on professor's lab website

LinkedIn Profile:
- Name: {profile_name}
- Headline: {headline}
- Education: {education}

Evaluation Criteria:
1. Name similarity (account for nicknames, middle names, name order variations)
2. University affiliation match (same institution?)
3. Degree program alignment (PhD, postdoc, etc.)
4. Timeline consistency (education dates align with lab membership?)

Provide:
1. Confidence score (0-100)
2. Reasoning for your assessment
3. Key matching/mismatching factors

Format your response as:
Confidence: <score>
Reasoning: <explanation>
"""
```

### Testing

**Test File Location:** `tests/unit/test_linkedin_profile_matching.py`

**Test Approach:** Unit tests with mocked LLM responses

**Key Test Scenarios:**

1. **High Confidence Match** (Unit)
   - Mock LLM to return confidence=95
   - Call `match_profile_with_llm()`
   - Assert confidence >= threshold (75)
   - Verify `linkedin_url` set, no quality flags

2. **Low Confidence Match** (Unit)
   - Mock LLM to return confidence=60
   - Call matching logic with threshold=75
   - Assert member flagged with `"low_confidence_linkedin_match"`
   - Verify `linkedin_url` not set

3. **Name Variations Handling** (Unit)
   - Test with variations: "John Smith" vs "J. Smith", "María García" vs "Maria Garcia"
   - Mock LLM to handle name similarity correctly
   - Assert high confidence for valid variations

4. **University Mismatch Detection** (Unit)
   - Mock LinkedIn profile with different university
   - Call matching logic
   - Assert affiliation mismatch flagged
   - Verify lower confidence score

5. **No Match Found** (Unit)
   - Mock LinkedIn search returning empty results
   - Call matching logic
   - Assert `linkedin_url = None`
   - Verify `data_quality_flags` contains `"no_linkedin_profile"`

6. **LLM Response Parsing** (Unit)
   - Mock various LLM response formats
   - Test regex parsing of confidence scores
   - Assert correct extraction of confidence value
   - Handle edge cases (missing confidence, malformed response)

**Success Criteria:**
- Confidence threshold correctly filters low-quality matches
- LLM prompt includes all relevant matching criteria
- Name variations handled gracefully
- University mismatches reduce confidence appropriately
- Missing profiles handled without crashes

**Test Data Requirements:**
- Sample LabMember objects with various names
- Mock LinkedIn profile responses
- Mock LLM responses with different confidence scores
- Configuration with test threshold values

**Example Test Pattern:**
```python
import pytest
from unittest.mock import AsyncMock, patch
from src.agents.linkedin_matcher import match_profile_with_llm
from src.models.lab_member import LabMember

@pytest.mark.asyncio
async def test_low_confidence_match_flagged():
    # Arrange
    member = LabMember(name="Jane Doe")
    profile = {"name": "Janet Doe", "university": "MIT", "headline": "PhD Student"}
    threshold = 75.0

    mock_llm_response = """
    Confidence: 60
    Reasoning: Name similarity moderate, but university matches. Timeline unclear.
    """

    with patch('src.utils.llm_helpers.call_llm_with_retry', return_value=mock_llm_response):
        # Act
        confidence, reasoning = await match_profile_with_llm(member, profile, "Stanford")

        # Assert
        assert confidence == 60
        assert confidence < threshold
        # Verify flag would be added in main logic
```

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-06 | 0.1 | Initial story creation | Sarah (PO) |
| 2025-10-06 | 0.2 | Added LLM integration pattern, confidence threshold details, expanded prompt template, testing guidance | Sarah (PO) |
