# Story 6.5: LinkedIn Error Handling & Logging

## Status

**Draft**

## Story

**As a** user,
**I want** LinkedIn access failures logged and handled gracefully,
**so that** LinkedIn issues don't block the entire analysis.

## Acceptance Criteria

1. Rate limiting detected and respected (NFR11)
2. MCP server errors handled with fallback
3. Profile access failures logged (NFR17)
4. Missing data handled gracefully (NFR13)
5. MCP unavailability doesn't crash system
6. Analysis continues with partial LinkedIn data if needed
7. All LinkedIn-specific failures isolated (don't crash system)

## Tasks / Subtasks

- [ ] **Task 1: Implement MCP Server Error Handling** (AC: 2, 5)
  - [ ] Catch `MCPConnectionError` exceptions
  - [ ] Catch `asyncio.TimeoutError` exceptions
  - [ ] Log errors with ERROR level including member context
  - [ ] Flag affected members with `"mcp_server_unavailable"`
  - [ ] Continue processing remaining members
  - [ ] Return partial results with quality flags

- [ ] **Task 2: Implement Rate Limit Handling** (AC: 1)
  - [ ] Catch `MCPRateLimitError` exceptions from mcp_client
  - [ ] Use retry decorator from Story 6.2 (exponential backoff)
  - [ ] Max 3 retry attempts per member
  - [ ] Log WARNING on each retry attempt
  - [ ] If retries exhausted: flag member `"rate_limit_exceeded"`, continue
  - [ ] Track rate limit events for reporting

- [ ] **Task 3: Handle Missing LinkedIn Data** (AC: 4, 6)
  - [ ] If search returns empty results: log INFO, flag `"no_linkedin_profile"`
  - [ ] If profile incomplete (missing education): log WARNING, flag `"incomplete_linkedin_data"`
  - [ ] If entry year unparseable: log WARNING, flag `"missing_entry_year"`
  - [ ] Never crash on missing data - always continue pipeline

- [ ] **Task 4: Implement Comprehensive Error Logging** (AC: 3, 7)
  - [ ] Use `logger.py` from Story 1.7 with correlation IDs
  - [ ] Log at appropriate levels (ERROR, WARNING, INFO)
  - [ ] Include context: member name, university, attempted action
  - [ ] Create error summary at end: "X/Y members matched, Z failed"
  - [ ] Write error details to checkpoint file for user review

- [ ] **Task 5: Implement Error Isolation** (AC: 7)
  - [ ] Wrap all LinkedIn operations in try-except blocks
  - [ ] Never allow LinkedIn errors to propagate to coordinator
  - [ ] Use `asyncio.gather(*tasks, return_exceptions=True)` for batch processing
  - [ ] Validate all exceptions are caught and handled

- [ ] **Task 6: Create Error Reporting Summary** (AC: 3)
  - [ ] Count successful matches, failures by type
  - [ ] Log summary at INFO level
  - [ ] Include summary in phase completion message
  - [ ] Example: "LinkedIn matching: 18/25 matched (72%), 5 no profile, 2 MCP errors"

## Dev Notes

### Source Tree Location
- Modify: `src/agents/linkedin_matcher.py`
- Use: `src/utils/logger.py` (from Story 1.7)
- Use: `src/utils/mcp_client.py` (from Story 1.5)
- Use: `src/models/lab_member.py` (from Story 6.3)

### Error Handling Patterns

#### Pattern 1: MCP Connection Error Handling

```python
from src.utils.mcp_client import search_linkedin_profile, MCPConnectionError
from src.utils.logger import get_logger
from src.models.lab_member import LabMember

logger = get_logger(correlation_id=run_id, phase="linkedin_matching", component="error_handler")

async def match_member_safe(member: LabMember, university: str) -> LabMember:
    """
    Match member to LinkedIn with comprehensive error handling.

    Returns:
        LabMember with LinkedIn data or error flags
    """
    try:
        profiles = await search_linkedin_profile(member.name, university)

        if not profiles:
            logger.info("No LinkedIn profile found", member=member.name)
            member.data_quality_flags.append("no_linkedin_profile")
            return member

        # Process profiles (matching logic from Story 6.3)
        # ...

    except MCPConnectionError as e:
        logger.error(
            "MCP server unavailable",
            member=member.name,
            university=university,
            error=str(e),
            error_type="MCPConnectionError"
        )
        member.data_quality_flags.append("mcp_server_unavailable")

    except asyncio.TimeoutError:
        logger.error(
            "LinkedIn search timeout",
            member=member.name,
            university=university,
            timeout_seconds=30,
            error_type="TimeoutError"
        )
        member.data_quality_flags.append("linkedin_timeout")

    except Exception as e:
        # Catch-all for unexpected errors
        logger.error(
            "Unexpected error in LinkedIn matching",
            member=member.name,
            error=str(e),
            error_type=type(e).__name__,
            exc_info=True  # Include stack trace
        )
        member.data_quality_flags.append("linkedin_error_unknown")

    return member
```

#### Pattern 2: Rate Limit Handling with Retry

```python
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from src.utils.mcp_client import MCPRateLimitError

@retry(
    retry=retry_if_exception_type(MCPRateLimitError),
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=2, min=2, max=30),
    reraise=False  # Don't reraise after max attempts
)
async def search_with_retry(member_name: str, university: str) -> list[dict]:
    """
    Search LinkedIn with automatic retry on rate limits.

    Returns:
        List of profiles or empty list if rate limit exceeded
    """
    try:
        return await search_linkedin_profile(member_name, university)
    except MCPRateLimitError as e:
        logger.warning(
            "Rate limit hit, retrying",
            member=member_name,
            attempt=e.retry_state.attempt_number if hasattr(e, 'retry_state') else 'unknown'
        )
        raise  # Trigger retry
```

#### Pattern 3: Batch Processing with Error Isolation

```python
import asyncio
from typing import List

async def match_all_members(members: List[LabMember], university: str) -> List[LabMember]:
    """
    Match all members to LinkedIn with isolated error handling.

    Uses asyncio.gather with return_exceptions=True to ensure
    one member's failure doesn't affect others.

    Returns:
        List of LabMembers with LinkedIn data or error flags
    """
    # Create tasks for all members
    tasks = [match_member_safe(member, university) for member in members]

    # Execute in parallel, catching exceptions per task
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # Process results
    processed_members = []
    errors = []

    for member, result in zip(members, results):
        if isinstance(result, Exception):
            # Unexpected exception that escaped match_member_safe
            logger.critical(
                "Unhandled exception in member matching",
                member=member.name,
                error=str(result),
                error_type=type(result).__name__
            )
            member.data_quality_flags.append("critical_error")
            errors.append((member.name, result))
            processed_members.append(member)
        else:
            processed_members.append(result)

    # Log batch summary
    success_count = sum(1 for m in processed_members if m.linkedin_url is not None)
    logger.info(
        "LinkedIn batch matching complete",
        total=len(members),
        successful=success_count,
        failed=len(members) - success_count,
        success_rate=f"{success_count/len(members)*100:.1f}%"
    )

    return processed_members
```

#### Pattern 4: Missing Data Handling

```python
def parse_entry_year(profile: dict, member_name: str) -> Optional[int]:
    """
    Parse entry year from LinkedIn profile with error handling.

    Returns:
        Entry year as int, or None if not found/unparseable
    """
    try:
        education = profile.get('education', [])

        if not education:
            logger.warning(
                "LinkedIn profile missing education section",
                member=member_name,
                profile_url=profile.get('url')
            )
            return None

        # Find PhD entry
        for edu in education:
            if 'PhD' in edu.get('degree', ''):
                start_date = edu.get('start_date', '')

                # Parse year from various formats
                import re
                year_match = re.search(r'\d{4}', str(start_date))

                if year_match:
                    return int(year_match.group(0))

        logger.warning(
            "Could not find PhD entry year in LinkedIn profile",
            member=member_name,
            education_count=len(education)
        )
        return None

    except (KeyError, ValueError, TypeError) as e:
        logger.warning(
            "Error parsing entry year from LinkedIn",
            member=member_name,
            error=str(e),
            error_type=type(e).__name__
        )
        return None
```

### Logging Standards (from Story 1.7)

**Logger Setup:**
```python
from src.utils.logger import get_logger

logger = get_logger(
    correlation_id=run_id,  # UUID for this pipeline run
    phase="linkedin_matching",
    component="linkedin_matcher"
)
```

**Log Levels:**

- **DEBUG:** Detailed flow (LLM prompts, MCP requests)
  ```python
  logger.debug("LinkedIn search query", name=member_name, university=university)
  ```

- **INFO:** Normal operations, phase progress
  ```python
  logger.info("Member matched to LinkedIn", member=member_name, confidence=95)
  ```

- **WARNING:** Missing data, low confidence, retries
  ```python
  logger.warning("Low confidence match", member=member_name, confidence=65, threshold=75)
  ```

- **ERROR:** Failures that skip individual items
  ```python
  logger.error("MCP server unavailable", member=member_name, error=str(e))
  ```

- **CRITICAL:** Unrecoverable failures requiring user intervention
  ```python
  logger.critical("All LinkedIn matching failed", total_members=25, error="MCP server down")
  ```

**Structured Logging Example:**
```python
logger.info(
    "LinkedIn matching complete",
    total_members=25,
    successful_matches=18,
    no_profile_found=5,
    mcp_errors=2,
    success_rate=72.0,
    duration_seconds=45.3
)
```

### Error Summary Reporting

```python
from collections import Counter

def generate_error_summary(members: List[LabMember]) -> dict:
    """
    Generate summary of LinkedIn matching results.

    Returns:
        Dictionary with counts by status and flags
    """
    total = len(members)
    matched = sum(1 for m in members if m.linkedin_url is not None)

    # Count data quality flags
    all_flags = [flag for m in members for flag in m.data_quality_flags]
    flag_counts = Counter(all_flags)

    summary = {
        "total_members": total,
        "matched": matched,
        "match_rate": round(matched / total * 100, 1) if total > 0 else 0,
        "no_profile": flag_counts.get("no_linkedin_profile", 0),
        "mcp_errors": flag_counts.get("mcp_server_unavailable", 0),
        "timeouts": flag_counts.get("linkedin_timeout", 0),
        "rate_limit_exceeded": flag_counts.get("rate_limit_exceeded", 0),
        "low_confidence": flag_counts.get("low_confidence_linkedin_match", 0)
    }

    logger.info("LinkedIn matching summary", **summary)

    return summary
```

### Testing

**Test File Location:** `tests/unit/test_linkedin_error_handling.py`

**Test Approach:** Unit tests with mocked failures

**Key Test Scenarios:**

1. **MCP Connection Failure** (Unit)
   - Mock `search_linkedin_profile()` to raise `MCPConnectionError`
   - Call `match_member_safe()`
   - Assert member flagged with `"mcp_server_unavailable"`
   - Assert processing continues (no exception raised)
   - Verify ERROR log entry created

2. **Rate Limit with Retry Success** (Unit)
   - Mock to raise `MCPRateLimitError` twice, then succeed
   - Call `search_with_retry()`
   - Assert 3 total attempts
   - Verify WARNING logs for retries
   - Assert successful result returned

3. **Rate Limit Retry Exhausted** (Unit)
   - Mock to always raise `MCPRateLimitError`
   - Call `search_with_retry()`
   - Assert 3 attempts made, then stops
   - Verify empty list returned (not exception)
   - Verify WARNING logs for all retries

4. **Timeout Handling** (Unit)
   - Mock to raise `asyncio.TimeoutError`
   - Call `match_member_safe()`
   - Assert member flagged with `"linkedin_timeout"`
   - Verify ERROR log with timeout context

5. **Missing LinkedIn Profile** (Unit)
   - Mock search to return empty list `[]`
   - Call `match_member_safe()`
   - Assert member flagged with `"no_linkedin_profile"`
   - Verify INFO log (not error - normal case)

6. **Batch Error Isolation** (Unit)
   - Create 5 members
   - Mock: member 1 succeeds, 2 MCP error, 3 succeeds, 4 timeout, 5 succeeds
   - Call `match_all_members()`
   - Assert all 5 members returned (no exceptions)
   - Assert 3 successful, 2 failed appropriately
   - Verify batch summary logged

7. **Missing Entry Year Parsing** (Unit)
   - Mock LinkedIn profile with no education section
   - Call `parse_entry_year()`
   - Assert `None` returned
   - Verify WARNING log created

8. **Unexpected Exception Caught** (Unit)
   - Mock to raise `ValueError` (unexpected)
   - Call `match_member_safe()`
   - Assert member flagged with `"linkedin_error_unknown"`
   - Verify ERROR log with stack trace
   - Assert processing continues

**Success Criteria:**
- All error types caught and handled gracefully
- No uncaught exceptions crash the system
- Appropriate log levels used for each error type
- Data quality flags accurately reflect error types
- Batch processing continues despite individual failures
- Error summary provides actionable information

**Test Data Requirements:**
- Mock exception types (MCPConnectionError, MCPRateLimitError, TimeoutError)
- Sample LabMember objects
- Mock LinkedIn profiles (complete, incomplete, empty)

**Example Test Pattern:**
```python
import pytest
from unittest.mock import AsyncMock, patch, MagicMock
from src.agents.linkedin_matcher import match_member_safe, match_all_members
from src.models.lab_member import LabMember
from src.utils.mcp_client import MCPConnectionError

@pytest.mark.asyncio
async def test_mcp_connection_error_handled():
    # Arrange
    member = LabMember(name="Jane Doe")

    with patch('src.utils.mcp_client.search_linkedin_profile') as mock_search:
        mock_search.side_effect = MCPConnectionError("Server down")

        # Act
        result = await match_member_safe(member, "Stanford")

        # Assert
        assert result.linkedin_url is None
        assert "mcp_server_unavailable" in result.data_quality_flags
        # Verify no exception raised (processing continues)

@pytest.mark.asyncio
async def test_batch_error_isolation():
    # Arrange
    members = [
        LabMember(name="Alice"),
        LabMember(name="Bob"),
        LabMember(name="Charlie")
    ]

    async def mock_match(member, university):
        if member.name == "Bob":
            raise MCPConnectionError("Test error")
        member.linkedin_url = f"https://linkedin.com/in/{member.name.lower()}"
        return member

    with patch('src.agents.linkedin_matcher.match_member_safe', side_effect=mock_match):
        # Act
        results = await match_all_members(members, "MIT")

        # Assert
        assert len(results) == 3  # All members returned
        assert results[0].linkedin_url is not None  # Alice succeeded
        assert results[1].linkedin_url is None  # Bob failed but handled
        assert results[2].linkedin_url is not None  # Charlie succeeded
```

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-06 | 0.1 | Initial story creation | Sarah (PO) |
| 2025-10-06 | 0.2 | Complete rewrite with concrete error patterns, logging examples, retry strategies, comprehensive testing | Sarah (PO) |
