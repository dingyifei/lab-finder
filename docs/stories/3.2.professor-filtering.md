# Story 3.2: LLM-Based Professor Research Field Filtering

## Status

**Draft**

## Story

**As a** user,
**I want** professors filtered based on research field alignment with my interests,
**so that** I only analyze labs that are potentially good fits.

## Acceptance Criteria

1. LLM analyzes each professor's research areas against user profile (FR11)
2. Matching logic: Include if ANY major research field overlaps with user interests
3. Interdisciplinary researchers appropriately handled (not over-filtered)
4. Major deviations excluded (e.g., literature professor for bioengineering student)
5. Edge cases handled: emerging fields, multi-disciplinary labs, co-appointments
6. Filtering uses consolidated research profile from Epic 1

## Tasks / Subtasks

- [ ] **Task 1: Load User Research Profile** (AC: 1, 6)
  - [ ] Load consolidated profile from `output/user-profile.md` (Story 1.4)
  - [ ] Extract research interests section
  - [ ] Extract degree program and academic background
  - [ ] Pass profile context to LLM filtering function

- [ ] **Task 2: Implement LLM-Based Professor Filtering** (AC: 1, 2, 3, 4)
  - [ ] Use `llm_helpers.py` prompt template for professor filtering (Story 1.7)
  - [ ] Prompt template:
    ```
    User Profile:
    - Research Interests: {interests}
    - Degree Program: {degree}
    - Background: {background}

    Professor:
    - Name: {professor_name}
    - Title: {title}
    - Research Areas: {research_areas}
    - Department: {department}

    Should this professor be included for further analysis?

    Guidelines:
    - Include if ANY major research field overlaps with user interests
    - Include interdisciplinary researchers
    - Include emerging/novel research areas related to user interests
    - Exclude only if research is completely unrelated

    Respond in JSON:
    {
      "decision": "include" | "exclude",
      "confidence": 0-100,
      "reasoning": "explanation of decision"
    }
    ```
  - [ ] Call LLM for each professor
  - [ ] Parse JSON response (decision, confidence, reasoning)

- [ ] **Task 3: Handle Interdisciplinary Researchers** (AC: 3, 5)
  - [ ] Ensure professors with multiple research areas get fair evaluation
  - [ ] If ANY research area matches user interests: INCLUDE
  - [ ] Example: CS professor researching computational biology → include for biology student
  - [ ] Edge case: Co-appointed professors (multiple departments) → evaluate all affiliations
  - [ ] Log interdisciplinary inclusions separately

- [ ] **Task 4: Handle Edge Cases** (AC: 5)
  - [ ] **Emerging Fields:** Include if conceptually related (e.g., "quantum ML" for ML student)
  - [ ] **Generic Descriptions:** If research areas vague (e.g., "various topics") → include by default
  - [ ] **Missing Research Areas:** If no research areas listed → include (investigate further in next phase)
  - [ ] **Multiple Departments:** Evaluate all department affiliations
  - [ ] Log edge cases with WARNING level for user review

- [ ] **Task 5: Update Professor Model with Filter Results** (AC: 1)
  - [ ] Add fields to Professor model:
    ```python
    is_relevant: bool = False  # Filter decision
    relevance_confidence: int = 0  # 0-100
    relevance_reasoning: str = ""  # LLM explanation
    ```
  - [ ] Set fields based on LLM filtering decision
  - [ ] Preserve all professors (both relevant and filtered) in checkpoint

- [ ] **Task 6: Implement Batch Processing for Filtering** (AC: 1)
  - [ ] Load professors in batches from `checkpoints/phase-2-professors-batch-*.jsonl`
  - [ ] Process each batch through LLM filtering
  - [ ] Use batch size from system config (professor_filtering_batch_size)
  - [ ] Save filtered results after each batch
  - [ ] Enable resumability from last completed batch

- [ ] **Task 7: Save Filtered Professors to Checkpoint** (AC: 1)
  - [ ] Save ALL professors (relevant + filtered) to updated checkpoint
  - [ ] Use checkpoint_manager.save_batch()
  - [ ] Save to `checkpoints/phase-2-professors-filtered-batch-{N}.jsonl`
  - [ ] Include filter decision, confidence, reasoning in serialized data

- [ ] **Task 8: Integrate Progress Tracking** (AC: 1)
  - [ ] Use progress_tracker from Story 1.7
  - [ ] Display: "Phase 2: Professor Filtering [X/Y professors processed]"
  - [ ] Show batch progress
  - [ ] Display summary: "X of Y professors included (Z% match rate)"

## Dev Notes

### Relevant Architecture Information

**Component:** Professor Filter Agent (Epic 3)

**Responsibility:** Filter professors by research field alignment using LLM (Epic 3: FR11)

**Key Interfaces:**
- `filter_professors(professors: list[Professor], profile: UserProfile) -> list[Professor]` - LLM-based filtering

**Dependencies:**
- LLM Helpers for prompt templates and LLM calls (Story 1.7)
- Professor data from Story 3.1 checkpoints
- User profile from Story 1.4
- Checkpoint Manager for saving results (Story 1.7)
- Progress Tracker for status updates (Story 1.7)

**Technology Stack:**
- Claude LLM via llm_helpers
- structlog with filtering context
- Pydantic Professor model with filter fields

**Source Tree Location:**
- Create: `src/agents/professor_filter.py`
- Modify: `src/models/professor.py` (add filter fields)
- Load from: `checkpoints/phase-2-professors-batch-*.jsonl`
- Save to: `checkpoints/phase-2-professors-filtered-batch-{N}.jsonl`

**Updated Professor Model:**
```python
class Professor(BaseModel):
    id: str
    name: str
    title: str
    department_id: str
    department_name: str
    school: Optional[str] = None
    lab_name: Optional[str] = None
    lab_url: Optional[str] = None
    research_areas: list[str] = []
    profile_url: str
    email: Optional[str] = None
    data_quality_flags: list[str] = []
    # Filter fields (Story 3.2)
    is_relevant: bool = False
    relevance_confidence: int = 0  # 0-100
    relevance_reasoning: str = ""
```

**LLM Prompt Template (from llm_helpers.py):**
```python
PROFESSOR_FILTER_PROMPT = """
User Profile:
- Research Interests: {interests}
- Degree Program: {degree}
- Background: {background}

Professor:
- Name: {professor_name}
- Title: {title}
- Research Areas: {research_areas}
- Department: {department}

Should this professor be included for further analysis?

Guidelines:
- Include if ANY major research field overlaps with user interests
- Include interdisciplinary researchers
- Include emerging/novel research areas related to user interests
- Exclude only if research is completely unrelated

Respond in JSON:
{{
  "decision": "include" | "exclude",
  "confidence": 0-100,
  "reasoning": "explanation of decision focusing on overlap areas or lack thereof"
}}
"""
```

**Filtering Philosophy:**
- **Inclusive by default:** ANY research overlap → include
- **Interdisciplinary friendly:** Multiple research areas evaluated holistically
- **Emerging fields:** Include conceptually related novel areas
- **Exclude only obvious mismatches:** E.g., literature for engineering, music for biology

**Batch Processing Pattern:**
```python
# Load professors in batches
resume_batch = checkpoint_manager.get_resume_point("phase-2-filter")
for batch_id in range(resume_batch, total_batches):
    professors_batch = load_professor_batch(batch_id)

    # Filter each professor in batch
    for professor in professors_batch:
        filter_result = llm_filter(professor, user_profile)
        professor.is_relevant = filter_result.decision == "include"
        professor.relevance_confidence = filter_result.confidence
        professor.relevance_reasoning = filter_result.reasoning

    # Save batch with filter results
    checkpoint_manager.save_batch("phase-2-filter", batch_id, professors_batch)
```

**Critical Rules (from Coding Standards):**
- All LLM calls must use llm_helpers module
- Never use print() for logging (use structlog)
- Always type hint function signatures
- Use checkpoint_manager.save_batch() - never write JSONL directly

**Architecture Component Diagram Flow:**
```
CLI Coordinator → Professor Filter Agent
Professor Filter Agent → Checkpoint Manager (load professors)
Professor Filter Agent → LLM Helpers (filter each professor)
Professor Filter Agent → Checkpoint Manager (save filtered results)
Professor Filter Agent → Progress Tracker (display progress)
```

### Testing

**Test File Location:** `tests/unit/test_professor_filter.py`

**Testing Standards:**
- Framework: pytest 7.4.4
- Mock LLM responses with pytest-mock
- Coverage requirement: 70% minimum

**Test Requirements:**
1. Unit test for filter_professors with mock LLM responses
2. Test inclusive filtering (ANY overlap includes professor)
3. Test exclusion of completely unrelated professors
4. Test interdisciplinary researcher handling
5. Test edge cases (emerging fields, missing research areas)
6. Test batch processing and checkpoint saving
7. Test confidence score assignment

**Example Test Pattern:**
```python
def test_filter_includes_interdisciplinary_professor(mocker):
    # Arrange
    mock_llm = mocker.patch('src.utils.llm_helpers.call_llm_with_retry')
    mock_llm.return_value = json.dumps({
        "decision": "include",
        "confidence": 85,
        "reasoning": "Computational biology overlaps with ML interests"
    })

    professor = Professor(
        id="prof-1",
        name="Dr. Jane Smith",
        research_areas=["Computational Biology", "Bioinformatics"],
        profile_url="https://prof.edu"
    )
    profile = UserProfile(research_interests="Machine Learning")

    agent = ProfessorFilterAgent()

    # Act
    filtered = agent.filter_professors([professor], profile)

    # Assert
    assert len(filtered) == 1
    assert filtered[0].is_relevant == True
    assert filtered[0].relevance_confidence == 85
```

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-06 | 0.1 | Initial story creation | Sarah (PO) |

## Dev Agent Record

### Agent Model Used

_To be populated by dev agent_

### Debug Log References

_To be populated by dev agent_

### Completion Notes List

_To be populated by dev agent_

### File List

_To be populated by dev agent_

## QA Results

_To be populated by QA agent_
