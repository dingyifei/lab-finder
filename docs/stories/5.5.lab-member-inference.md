# Story 5.5: Lab Member Inference from Co-Authorship

## Status

**Draft**

## Story

**As a** user,
**I want** lab members inferred from publication co-authorship when websites are missing or stale,
**so that** I still get comprehensive lab intelligence.

## Acceptance Criteria

1. When lab website unavailable or severely outdated, use publications (FR31)
2. Frequent co-authors on PI's papers identified as likely lab members
3. Co-authorship patterns analyzed (repeated collaboration over time)
4. Institutional affiliations checked to confirm same university
5. Inferred members flagged as "inferred from publications" in reports (FR32)
6. Confidence levels assigned to inferences
7. Inferred member list used for Story 5.4 publication discovery

## Tasks / Subtasks

- [ ] **Task 1: Identify Labs with Missing Member Data** (AC: 1)
  - [ ] Check if Lab.members is empty
  - [ ] Check if website stale (from Story 4.4)
  - [ ] Flag for member inference

- [ ] **Task 2: Extract Co-Authors from PI Publications** (AC: 2)
  - [ ] Get all PI publications
  - [ ] Extract co-author names
  - [ ] Count co-authorship frequency

- [ ] **Task 3: Analyze Co-Authorship Patterns** (AC: 3)
  - [ ] Identify frequent collaborators (>= 2 papers)
  - [ ] Check temporal patterns (across multiple years)

- [ ] **Task 4: Verify University Affiliation** (AC: 4)
  - [ ] Check author affiliations in papers
  - [ ] Confirm same university as PI

- [ ] **Task 5: Create Inferred Member Records** (AC: 5, 6)
  - [ ] Create LabMember model instances
  - [ ] Flag: `data_quality_flags: ["inferred_from_coauthorship"]`
  - [ ] Assign confidence based on frequency

- [ ] **Task 6: Update Lab Model** (AC: 7)
  - [ ] Add inferred members to Lab.members
  - [ ] Use for publication retrieval in Story 5.4

## Dependencies

**Depends On:**
- **Epic 4 complete** (determines which lab websites are missing/stale - AC 1)
- **Epic 5A complete** (provides PI publications for co-author extraction - AC 2)
- Story 5.4 complete (may have already populated some member data)

**Convergence Point:**
This story is part of Epic 5B and requires **both Epic 4 and Epic 5A to be complete**. AC 1 depends on Epic 4 website freshness flags, and AC 2 depends on Epic 5A PI publications.

**Blocks:**
- Epic 6 (LinkedIn Integration) - inferred members will be matched to LinkedIn

## Testing

### Test Approach

**Unit Tests:**
- Missing/stale member data detection logic
- Co-author extraction from publication author lists
- Co-authorship frequency counting (threshold >= 2)
- University affiliation checking
- Confidence score calculation
- LabMember object creation with inference flags
- Data quality flag assignment

**Integration Tests:**
- End-to-end inference for lab with missing website
- Integration with Story 5.4 (using inferred members for publication discovery)
- Epic 4 website freshness flag reading

**Mocking Strategy:**
- Mock Epic 4 checkpoint with labs flagged as stale/missing
- Mock Epic 5A PI publications with varying co-author patterns
- Mock LLM for affiliation validation
- Use pytest fixtures for test data

**Test Framework:**
- pytest 7.4.4
- pytest-asyncio 0.23.3 for async affiliation checks
- pytest-mock 3.12.0 for checkpoint mocking

### Key Test Scenarios

**1. Identify Labs with Missing Member Data**
- Input: Lab with empty Lab.members list
- Expected: Lab flagged for inference
- Validates: AC 1 - Missing member data detected

**2. Identify Labs with Stale Website**
- Input: Lab with website_last_updated > 2 years ago
- Expected: Lab flagged for inference
- Validates: AC 1 - Stale websites trigger inference

**3. Frequent Co-Author Inference**
- Input: PI with 5 papers, "Alice Johnson" appears on 3 papers
- Expected: Alice Johnson inferred as lab member (>= 2 threshold)
- Validates: AC 2, 3 - Frequent co-authors identified

**4. Infrequent Co-Author Exclusion**
- Input: PI with 5 papers, "Bob Smith" appears on 1 paper
- Expected: Bob Smith NOT inferred (< 2 threshold)
- Validates: AC 3 - Threshold filtering works

**5. University Affiliation Verification**
- Input: Frequent co-author with same university affiliation
- Expected: Affiliation confirmed, confidence score high
- Validates: AC 4 - Institutional affiliations checked

**6. Different University Exclusion**
- Input: Frequent co-author from different university
- Expected: NOT inferred as lab member, or flagged with low confidence
- Validates: AC 4 - External collaborators filtered out

**7. Confidence Score Calculation**
- Input: Co-author on 2, 3, 5 papers
- Expected: Confidence scores of 40, 60, 100 respectively (per algorithm)
- Validates: AC 6 - Confidence levels assigned correctly

**8. Data Quality Flagging**
- Input: Inferred lab member
- Expected: data_quality_flags contains "inferred_from_coauthorship"
- Validates: AC 5 - Inferred members flagged appropriately

**9. Temporal Co-Authorship Patterns**
- Input: Co-author on papers spanning multiple years (2022, 2023, 2024)
- Expected: Higher confidence for sustained collaboration
- Validates: AC 3 - Temporal patterns analyzed

**10. Integration with Story 5.4**
- Input: Inferred member list added to Lab.members
- Expected: Story 5.4 uses inferred members for publication retrieval
- Validates: AC 7 - Inferred members usable downstream

### Success Criteria

- ✅ Labs with missing/stale data correctly identified (100% detection)
- ✅ Frequent co-authors (>= 2 papers) inferred with high confidence (>80)
- ✅ Infrequent co-authors (< 2 papers) excluded from inference
- ✅ Same-university affiliation verified correctly (>90% accuracy)
- ✅ Different-university collaborators filtered out
- ✅ Confidence scores calculated correctly per algorithm
- ✅ All inferred members flagged with "inferred_from_coauthorship"
- ✅ Inferred members successfully used in Story 5.4
- ✅ Test coverage >80% for inference algorithm

### Special Testing Considerations

**Inference Algorithm Testing:**
```python
def test_infer_lab_members_threshold():
    """Test inference with >= 2 paper threshold"""
    pi_pubs = [
        Publication(authors=["Jane Smith", "Alice Johnson"]),  # Alice: 1
        Publication(authors=["Jane Smith", "Alice Johnson"]),  # Alice: 2 ✓
        Publication(authors=["Jane Smith", "Bob Chen"]),       # Bob: 1
        Publication(authors=["Jane Smith", "Alice Johnson"]),  # Alice: 3 ✓
        Publication(authors=["Jane Smith", "Carol Davis"]),    # Carol: 1
        Publication(authors=["Jane Smith", "Carol Davis"]),    # Carol: 2 ✓
    ]

    inferred = infer_lab_members(pi_pubs, pi_name="Jane Smith")

    # Should infer Alice (3 papers) and Carol (2 papers)
    # Should NOT infer Bob (1 paper)
    assert len(inferred) == 2
    assert "Alice Johnson" in [m.name for m in inferred]
    assert "Carol Davis" in [m.name for m in inferred]
    assert "Bob Chen" not in [m.name for m in inferred]

def test_confidence_score_calculation():
    """Test confidence based on co-authorship frequency"""
    pi_pubs = [
        Publication(authors=["PI", "Alice"]) for _ in range(5)  # 5 papers
    ]

    inferred = infer_lab_members(pi_pubs, pi_name="PI")

    alice = [m for m in inferred if m.name == "Alice"][0]

    # Algorithm: min(count * 20, 100)
    # 5 papers * 20 = 100
    assert alice.confidence == 100
```

**Affiliation Validation Testing:**
```python
@pytest.mark.asyncio
async def test_affiliation_verification_same_university(mocker):
    """Test affiliation check for same-university co-author"""
    mocker.patch('src.agents.publication_retrieval.validate_affiliation',
                 return_value=True)

    member = LabMember(name="Alice Johnson", inferred=True)
    result = await verify_affiliation(member, university="Stanford")

    assert result is True  # Same university confirmed

@pytest.mark.asyncio
async def test_affiliation_verification_different_university(mocker):
    """Test external collaborator detection"""
    mocker.patch('src.agents.publication_retrieval.validate_affiliation',
                 return_value=False)

    member = LabMember(name="Bob Smith", inferred=True)
    result = await verify_affiliation(member, university="Stanford")

    assert result is False  # Different university, likely external
```

**Temporal Pattern Testing:**
```python
def test_temporal_coauthorship_patterns():
    """Test sustained collaboration detection"""
    pi_pubs = [
        Publication(authors=["PI", "Alice"], year=2022),
        Publication(authors=["PI", "Alice"], year=2023),
        Publication(authors=["PI", "Alice"], year=2024),
        Publication(authors=["PI", "Bob"], year=2024),
        Publication(authors=["PI", "Bob"], year=2024),
    ]

    inferred = infer_lab_members(pi_pubs, pi_name="PI")

    # Alice: 3 years of collaboration (sustained)
    # Bob: 1 year of collaboration (recent)
    # Alice should have higher confidence or priority
    alice = [m for m in inferred if m.name == "Alice"][0]
    bob = [m for m in inferred if m.name == "Bob"][0]

    # Could add temporal bonus to confidence
    assert alice.confidence >= bob.confidence
```

**Data Quality Flagging:**
```python
def test_inferred_member_flags():
    """Test data quality flags on inferred members"""
    pi_pubs = [
        Publication(authors=["PI", "Alice"]),
        Publication(authors=["PI", "Alice"]),
    ]

    inferred = infer_lab_members(pi_pubs, pi_name="PI")

    alice = inferred[0]
    assert alice.inferred is True
    assert "inferred_from_coauthorship" in alice.data_quality_flags
```

**Stale Website Detection:**
```python
def test_stale_website_triggers_inference():
    """Test labs with old websites flagged for inference"""
    from datetime import datetime, timedelta

    lab = Lab(
        pi_name="Jane Smith",
        website_last_updated=datetime.now() - timedelta(days=800),  # >2 years
        members=[]
    )

    needs_inference = should_infer_members(lab)
    assert needs_inference is True
```

**Edge Cases:**
- PI as co-author (should be excluded from co-author list)
- Same name, different people (affiliation helps disambiguate)
- Name variations (J. Smith vs Jane Smith)
- Very large co-author lists (>10 authors per paper)
- Papers with only PI as author

**Integration with Story 5.4:**
- Test inferred members added to Lab.members
- Verify Story 5.4 can query publications for inferred members
- Validate inferred flag propagates through pipeline

## Dev Notes

### Source Tree Location
- Modify: `src/agents/publication_retrieval.py`
- Create: `src/models/lab_member.py`

**Inference Logic:**
```python
def infer_lab_members(pi_pubs: list[Publication]) -> list[LabMember]:
    coauthor_freq = Counter()
    for pub in pi_pubs:
        for author in pub.authors:
            if author != pi_name:
                coauthor_freq[author] += 1

    # Threshold: >= 2 papers
    likely_members = [name for name, count in coauthor_freq.items() if count >= 2]
    return [LabMember(name=name, inferred=True, confidence=min(count*20, 100))
            for name in likely_members]
```

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-06 | 0.1 | Initial story creation | Sarah (PO) |
