# Story 5.3: Journal Reputation Weighting

## Status

**Draft**

## Story

**As a** user,
**I want** publications weighted by journal reputation,
**so that** high-impact publications are prioritized in fitness scoring.

## Acceptance Criteria

1. Journal reputation database integrated (SJR or Impact Factor) (FR17)
2. Each publication's journal matched to reputation score
3. Reputation scores normalized to consistent scale
4. Missing journal ratings handled (use citation count or default weight)
5. Conference papers handled appropriately (common in CS/engineering)
6. Reputation data cached to avoid repeated lookups
7. Weighting factors configurable in system parameters

## Tasks / Subtasks

- [ ] **Task 1: Integrate Journal Reputation Database** (AC: 1)
  - [ ] Use SJR (Scimago Journal Rank) or Impact Factor API
  - [ ] Implement lookup function
  - [ ] Cache results locally

- [ ] **Task 2: Match Publications to Journal Scores** (AC: 2)
  - [ ] For each publication, lookup journal reputation
  - [ ] Store in Publication.journal_reputation_score

- [ ] **Task 3: Normalize Scores** (AC: 3)
  - [ ] Normalize to 0-100 scale
  - [ ] Handle different reputation metrics

- [ ] **Task 4: Handle Missing Ratings** (AC: 4)
  - [ ] If journal not found, use citation count
  - [ ] Default weight: 50

- [ ] **Task 5: Update Publication Model** (AC: 2)
  - [ ] Add field: `journal_reputation_score: int = 50`

## Dependencies

**Depends On:**
- Story 5.1 complete (publication retrieval - provides journal names)
- Story 5.2 complete (abstract analysis - completes first enrichment pass)

**Execution Model:**
- Runs WITHIN `src/agents/publication_retrieval.py` as FINAL step of Epic 5A
- Executes in-order: Story 5.1 → 5.2 → **5.3** → Checkpoint save
- Modifies Publication objects in-place (adds journal_reputation_score)
- NOT a separate agent or file

**Data Flow:**
1. Input: Publication objects from Story 5.2 (with title, authors, journal, year, abstract, relevance_score)
2. Processing: Lookup journal reputation from SJR CSV database
3. Output: Fully enriched Publication objects saved to checkpoint

**Technical Context:**
- SJR database loaded at agent startup (per `docs/architecture.md#publication-retrieval-agent`)
- Uses pandas to load `data/scimago-journal-rank.csv`
- Journal lookup performed for each publication before checkpoint save

**Blocks:**
- Epic 5B (provides fully weighted PI publications for fitness scoring)

**Reference:**
- Agent Definition: `docs/architecture.md` (lines 827-856, Publication Retrieval Agent)
- Step 2: "Lookup journal SJR score from data/scimago-journal-rank.csv"

## Testing

### Test Approach

**Unit Tests:**
- SJR CSV loading and parsing with pandas
- Journal name matching (exact match)
- Journal name fuzzy matching (for slight variations)
- Score normalization (SJR to 0-100 scale)
- Missing journal fallback logic (citation count, default 50)
- Conference paper handling
- Cache validation (ensure CSV loaded only once)

**Integration Tests:**
- End-to-end journal scoring for batch of publications
- SJR database lookup performance
- Publication enrichment with journal scores

**Mocking Strategy:**
- Use small test SJR CSV fixture (`tests/fixtures/test_sjr.csv`) for unit tests
- Mock pandas read_csv for isolated unit tests
- Integration tests use real SJR CSV subset (100-200 journals)

**Test Framework:**
- pytest 7.4.4
- pytest-mock 3.12.0 for CSV mocking
- pandas 2.1.4 for CSV operations

### Key Test Scenarios

**1. Successful Journal Lookup**
- Input: Publication with journal="Nature"
- Expected: journal_reputation_score assigned (e.g., 95)
- Validates: AC 1, 2 - Journal matched and score assigned

**2. Journal Name Normalization**
- Input: Journal names with slight variations ("Nature Robotics" vs "Nature robotics")
- Expected: Case-insensitive matching finds correct journal
- Validates: Fuzzy matching handles common variations

**3. Missing Journal Rating**
- Input: Publication with journal="Obscure Conference 2024"
- Expected: Fallback to citation count or default 50
- Validates: AC 4 - Missing journal ratings handled

**4. Conference Paper Handling**
- Input: Publication with journal="NeurIPS 2024" (conference, not in SJR)
- Expected: Citation count used or default 50 assigned
- Validates: AC 5 - Conference papers handled appropriately

**5. Score Normalization**
- Input: SJR score of 1.85 (raw SJR value)
- Expected: Normalized to 0-100 scale (e.g., 85)
- Validates: AC 3 - Scores normalized to consistent scale

**6. Batch Publication Scoring**
- Input: 20 publications with mix of journals
- Expected: All assigned journal_reputation_score, no errors
- Validates: Pipeline efficiency, handles mix of found/missing journals

**7. CSV Load Performance**
- Input: Agent initialization
- Expected: SJR CSV loaded once, cached for all publications
- Validates: AC 6 - Reputation data cached, not reloaded per publication

**8. Configurable Weighting Factors**
- Input: System parameter for SJR weight multiplier
- Expected: Scores adjusted by configured weight
- Validates: AC 7 - Weighting factors configurable

### Success Criteria

- ✅ SJR CSV loads successfully at agent startup (< 2 seconds)
- ✅ Journal lookups succeed for 100% of journals in SJR database
- ✅ Missing journals handled gracefully (citation fallback or default 50)
- ✅ All scores normalized to 0-100 range
- ✅ Case-insensitive matching works for journal names
- ✅ Conference papers don't crash processing
- ✅ CSV loaded exactly once per agent instance (cache validated)
- ✅ Batch of 100 publications scored in < 1 second (CSV already loaded)
- ✅ Test coverage >80% for journal scoring functions

### Special Testing Considerations

**SJR CSV Test Fixture:**
```python
# tests/fixtures/test_sjr.csv
Journal,SJR,Category
Nature,11.329,Multidisciplinary
Science,10.212,Multidisciplinary
Nature Robotics,5.432,Robotics
IEEE Trans. Robotics,3.821,Robotics
PLOS ONE,0.885,Multidisciplinary

# Test using fixture
@pytest.fixture
def mock_sjr_df():
    return pd.DataFrame({
        'Journal': ['Nature', 'Science', 'Nature Robotics'],
        'SJR': [11.329, 10.212, 5.432]
    })

def test_assign_journal_score(mock_sjr_df):
    agent = PublicationRetrievalAgent()
    agent.sjr_df = mock_sjr_df  # Inject test data

    pub = Publication(journal="Nature", title="Test", authors=["Smith"])
    agent.assign_journal_score(pub)

    assert pub.journal_reputation_score > 90  # High score for Nature
    assert 0 <= pub.journal_reputation_score <= 100
```

**Normalization Testing:**
- Test SJR range mapping: 0-1 → 0-40, 1-5 → 40-70, 5+ → 70-100
- Validate non-linear scaling for better differentiation
- Ensure top journals (Nature, Science) score 95-100

**Missing Journal Fallback Logic:**
```python
def test_missing_journal_citation_fallback():
    pub = Publication(
        journal="Unknown Conference 2024",
        citations=25,
        title="Test",
        authors=["Smith"]
    )

    agent.assign_journal_score(pub)

    # Should use citation count (capped at 100)
    assert pub.journal_reputation_score == 25

def test_missing_journal_default():
    pub = Publication(
        journal="Unknown Journal",
        citations=0,  # No citations
        title="Test",
        authors=["Smith"]
    )

    agent.assign_journal_score(pub)

    # Should use default
    assert pub.journal_reputation_score == 50
```

**Conference Paper Testing:**
- Create fixtures for common CS conferences: NeurIPS, ICML, CVPR
- Validate fallback logic applies
- Test that conference papers don't break journal lookup

**Cache Validation:**
- Use mock to count pandas.read_csv calls
- Ensure exactly 1 call during agent initialization
- Validate 0 additional calls during publication processing

**Edge Cases:**
- Empty journal name
- Journal name with special characters
- Very long journal names
- Non-ASCII characters in journal names

## Dev Notes

### Integration with Epic 5A Pipeline

**IMPORTANT:** This story does NOT create a separate agent or file. Implementation goes in:
- **Modify:** `src/agents/publication_retrieval.py` (created in Story 5.1)
- **Modify:** `src/models/publication.py` (add journal_reputation_score field)

**Execution Order within publication_retrieval.py:**
1. Story 5.1: `fetch_publications()` - Query paper-search-mcp
2. Story 5.2: `analyze_abstracts()` - LLM relevance scoring
3. **Story 5.3: `assign_journal_scores()` - SJR lookup (THIS STORY)**
4. Save to checkpoint: `checkpoints/phase-5a-pi-publications-batch-{N}.jsonl`

### SJR Database Implementation

**Database Source (per architecture):**
- **File:** `data/scimago-journal-rank.csv`
- **Loading:** Once at agent startup (NOT per-publication API calls)
- **Library:** pandas 2.1.4 for CSV processing
- **Reference:** `docs/architecture.md` (line 1174: "Scimago SJR CSV database (loaded once at startup)")

**Implementation Pattern:**
```python
import pandas as pd

class PublicationRetrievalAgent:
    def __init__(self):
        # Load SJR database once at startup
        self.sjr_df = pd.read_csv("data/scimago-journal-rank.csv")

    async def assign_journal_scores(self, publications: list[Publication]) -> None:
        """Story 5.3: Assign journal reputation scores"""
        for pub in publications:
            try:
                # Lookup journal in SJR database
                score = self.sjr_df[self.sjr_df['Journal'] == pub.journal]['SJR'].values[0]
                pub.journal_reputation_score = int(score * 100)  # Normalize to 0-100
            except (IndexError, KeyError):
                # Journal not found - use fallback
                if pub.citations > 0:
                    pub.journal_reputation_score = min(pub.citations, 100)
                else:
                    pub.journal_reputation_score = 50  # Default
```

**Conference Papers (AC 5):**
- Many CS/engineering conferences not in SJR database
- Use citation count as fallback indicator
- Default to score of 50 if no citation data

### Source Tree Location
- Modify: `src/agents/publication_retrieval.py`
- Modify: `src/models/publication.py`

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-06 | 0.1 | Initial story creation | Sarah (PO) |
