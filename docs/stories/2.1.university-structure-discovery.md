# Story 2.1: University Website Structure Discovery

## Status

**Draft**

## Story

**As a** user,
**I want** the system to automatically discover my target university's organizational structure,
**so that** it can comprehensively search all relevant departments without manual mapping.

## Acceptance Criteria

1. System uses university core website link from config to discover structure (FR7)
2. Multi-layered hierarchies identified (schools → divisions → departments)
3. Department names, URLs, and relationships extracted
4. Built-in web tools used as primary method for discovery (NFR5)
5. Playwright fallback with screenshots when built-in tools fail
6. Progress indicators show discovery status (NFR14)

## Tasks / Subtasks

- [ ] **Task 1: Implement University Structure Discovery Agent** (AC: 1, 2, 3)
  - [ ] Create `src/agents/university_discovery.py` module
  - [ ] Implement `discover_structure(university_url: str) -> list[Department]` function
  - [ ] Use Claude Agent SDK built-in web tools as primary scraping method
  - [ ] Extract department hierarchy (schools, divisions, departments)
  - [ ] Extract department names, URLs, and parent relationships
  - [ ] Build hierarchical Department model instances with hierarchy_level attribute

- [ ] **Task 2: Implement Web Scraping with Fallback Pattern** (AC: 4, 5)
  - [ ] Try Claude Agent SDK built-in web fetch/scrape tools first
  - [ ] On failure, fallback to Playwright for JS-heavy pages
  - [ ] Implement retry logic with tenacity (3 retries, exponential backoff)
  - [ ] Add timeout handling (30 seconds per page per architecture)
  - [ ] Log which method was used (built-in vs Playwright) for each page
  - [ ] If both fail, skip page with data quality flag

- [ ] **Task 3: Spawn Sub-Agents for Parallel Discovery** (AC: 2)
  - [ ] Implement hierarchical coordinator pattern from architecture
  - [ ] Spawn sub-agents per school/division for parallel discovery
  - [ ] Aggregate results from all sub-agents
  - [ ] Handle sub-agent failures gracefully (continue with partial results)

- [ ] **Task 4: Integrate Progress Tracking** (AC: 6)
  - [ ] Use `progress_tracker.py` utility from Story 1.7
  - [ ] Display: "Phase 1: University Discovery [X/Y schools processed]"
  - [ ] Show progress for sub-agent operations
  - [ ] Display ETA for discovery completion

- [ ] **Task 5: Create Department Pydantic Models** (AC: 2, 3)
  - [ ] Create `src/models/department.py` module
  - [ ] Define Department Pydantic model with fields:
    - `id: str` - Unique identifier (generated)
    - `name: str` - Department name
    - `school: Optional[str]` - Parent school/college
    - `division: Optional[str]` - Parent division
    - `url: str` - Department homepage URL
    - `hierarchy_level: int` - Depth in organizational tree
  - [ ] Add type hints and validation
  - [ ] Run mypy to verify type correctness

- [ ] **Task 6: Save Discovery Results to Checkpoint** (AC: 3)
  - [ ] Use `checkpoint_manager.py` from Story 1.7
  - [ ] Save discovered departments to `checkpoints/phase-1-departments.jsonl`
  - [ ] Use JSONL format for streaming support
  - [ ] Serialize Department models with `.model_dump()`
  - [ ] Verify checkpoint file created and readable

## Dev Notes

### Relevant Architecture Information

**Component:** University Structure Discovery Agent (Epic 2)

**Responsibility:** Discover department hierarchy; filter relevant departments (Epic 2: FR7-FR9)

**Key Interfaces:**
- `discover_structure(university_url: str) -> list[Department]` - Scrape and map department tree
- `filter_departments(departments: list[Department], profile: UserProfile) -> list[Department]` - LLM-based relevance filtering (Story 2.3)

**Dependencies:**
- Claude Agent SDK built-in web tools (primary)
- Playwright (fallback for JS-heavy pages)
- LLM for department relevance assessment (Story 2.3)
- Checkpoint Manager for saving department structure

**Technology Stack:**
- Claude Agent SDK web fetch tools
- Playwright 1.40.0 as fallback
- structlog with phase context

**Agent Pattern:** Spawns sub-agents per school/division for parallel discovery; coordinator aggregates results

**Source Tree Location:**
- Create: `src/agents/university_discovery.py`
- Create: `src/models/department.py`
- Checkpoint output: `checkpoints/phase-1-departments.jsonl`

**Data Model (from Architecture):**

Department model:
```python
class Department(BaseModel):
    id: str  # Unique identifier (generated)
    name: str  # Department name
    school: Optional[str] = None  # Parent school/college
    division: Optional[str] = None  # Parent division
    url: str  # Department homepage URL
    hierarchy_level: int  # Depth in organizational tree (0=school, 1=division, 2=department)
    is_relevant: bool  # Result of relevance filtering (set in Story 2.3)
    relevance_reasoning: str  # LLM explanation (set in Story 2.3)
```

**Web Scraping Strategy (from Architecture):**

**Tiered Fallback:** Built-in → Playwright → Skip with Flag

**Recommendation:** Try Claude Agent SDK built-in tools first, fallback to Playwright, skip if both fail

**Rationale:**
- NFR5: "built-in web tools as primary, Playwright as fallback"
- Built-in tools faster and simpler for public pages
- Playwright needed for JS-heavy sites
- Skip with data quality flag if both fail (don't crash pipeline)

**Error Handling Pattern:**
- Retry Policy: Exponential backoff with jitter (tenacity library)
  - Max retries: 3
  - Initial delay: 1 second
  - Backoff multiplier: 2x
  - Max delay: 10 seconds
- Timeout Configuration: Web scraping: 30 seconds per page
- Error Translation:
  - HTTP 404 (Not Found) → Flag as missing data, continue
  - Network timeouts → Retry with exponential backoff

**Critical Rules (from Coding Standards):**
- Web scraping must try built-in tools first: Pattern: `try built-in → except → fallback to Playwright → except → flag and skip`
- Always type hint function signatures
- Never use print() for logging (use structlog)
- Use checkpoint_manager.save_batch() - never write JSONL directly

**Architecture Component Diagram Flow:**
```
CLI Coordinator → Configuration Validator → University Discovery Agent
University Discovery Agent → Checkpoint Manager (saves phase-1-departments.jsonl)
University Discovery Agent → Progress Tracker (displays progress)
```

### Testing

**Test File Location:** `tests/integration/test_university_discovery.py`

**Testing Standards:**
- Framework: pytest 7.4.4
- Integration tests with mock HTML files in `tests/fixtures/`
- Coverage requirement: 70% minimum

**Test Requirements:**
1. Unit test for Department model validation
2. Integration test with mock university structure HTML
3. Test web scraping fallback (built-in failure → Playwright success)
4. Test error handling (both methods fail → graceful degradation)
5. Test sub-agent spawning and aggregation
6. Test checkpoint saving (verify JSONL format)

**Example Test Pattern:**
```python
def test_discover_structure_with_mock_html(tmp_path):
    # Arrange
    mock_html_path = "tests/fixtures/mock_university_structure.html"
    agent = UniversityDiscoveryAgent(checkpoint_dir=tmp_path)

    # Act
    departments = agent.discover_structure("https://test.edu")

    # Assert
    assert len(departments) > 0
    assert all(isinstance(d, Department) for d in departments)
    assert all(d.hierarchy_level >= 0 for d in departments)
```

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-06 | 0.1 | Initial story creation | Sarah (PO) |

## Dev Agent Record

### Agent Model Used

_To be populated by dev agent_

### Debug Log References

_To be populated by dev agent_

### Completion Notes List

_To be populated by dev agent_

### File List

_To be populated by dev agent_

## QA Results

_To be populated by QA agent_
